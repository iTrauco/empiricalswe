[<div class="wiki-body gollum-markdown-content instapaper_body" id="wiki-body">
        <div class="markdown-body">
          <h1>
<a aria-hidden="true" class="anchor" href="#classifiers" id="user-content-classifiers"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z" fill-rule="evenodd"></path></svg></a>Classifiers</h1>
<p>A number of different classifiers were explored. The single biggest issue with training and utilizing classification algorithms was the need for processing speed.</p>
<p>The following were tried:</p>
<ul>
<li>Simple Trees</li>
<li>Random Forests</li>
<li>Extra Trees</li>
<li>Stochastic Gradient Descent, with Support Vector Machine</li>
<li>Ada Boosting</li>
<li>Logistic Regression</li>
<li>Multi-layered Perceptron (implemented in C)</li>
</ul>
<p>In the final analysis only 3 classifiers were utilized.</p>
<ol>
<li>Logistic regression was used once. It took a number of hours to train, but the final results in one particular instance were the best.</li>
<li>Extra Trees. Again used once based on performance.</li>
<li>Random Forests. The mainstay classifier of this project.</li>
</ol>
<p>The most significant reason for utilizing Random Forests, almost exclusively, was due to the fact that these two algorithms have sklearn implementations that can utilize multithreading. Random Forests (and Extra Trees) can, therefore, utilize multiple cores on the host machine. This reduced processing time to train the classifier to minutes.</p>
<h2>
<a aria-hidden="true" class="anchor" href="#solutions" id="user-content-solutions"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z" fill-rule="evenodd"></path></svg></a>Solutions</h2>
<p>Two solutions were attempted:</p>
<ol>
<li>A series of simpler classifiers arranged in a cascade, and</li>
<li>A single 10 class classifier</li>
</ol>
<h3>
<a aria-hidden="true" class="anchor" href="#the-cascade-solution" id="user-content-the-cascade-solution"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z" fill-rule="evenodd"></path></svg></a>The Cascade Solution</h3>
<p>The cascade solution was investigated on the premise that the features extracted from the images were not powerful enough to really separate the 10 classes adequately. Under this assertion was there a benefit to creating a set of simpler classifiers that might perform much better? The following diagram illustrates the cascade. The overall accuracy of this model was <strong>47%</strong>.
Details of the approach as a cascading classification problem may be found in the notebook "GA-PROJECT-RESULTS-CASCADE".</p>
<p><img alt="" data-canonical-src="http://www.chilledimage.com/images/cascade_diagram.jpg" src="https://camo.githubusercontent.com/9a1ec8f61ef1a59ece3d2963cb99110ef9a6d2ba/687474703a2f2f7777772e6368696c6c6564696d6167652e636f6d2f696d616765732f636173636164655f6469616772616d2e6a7067"/></p>
<h3>
<a aria-hidden="true" class="anchor" href="#the-ten-class-solution" id="user-content-the-ten-class-solution"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z" fill-rule="evenodd"></path></svg></a>The Ten Class Solution</h3>
<p>The best ten class classifier turned out to be a logistic regression model.
The overall accuracy of the model was <strong>54%</strong>.
Details of the approach as a ten class problem may be found in the notebook "GA-PROJECT-RESULTS-TENCLASS".</p>
<p><img alt="" data-canonical-src="http://www.chilledimage.com/images/ten_class.jpg" src="https://camo.githubusercontent.com/4dc05e6d4581743977cf639edb9079c1ece17a79/687474703a2f2f7777772e6368696c6c6564696d6167652e636f6d2f696d616765732f74656e5f636c6173732e6a7067"/></p>
<p>Key:</p>
<p>0 = frog, 1 = truck, 2 = deer, 3 = automobile, 4 = bird, 5 = cat, 6 = dog, 7 = horse, 8= ship, 9 = airplane</p>
<p><img alt="" data-canonical-src="http://www.chilledimage.com/images/tenclassctab.jpg" src="https://camo.githubusercontent.com/cf0f8df081378eb8f30ee9dc36337892e33e651a/687474703a2f2f7777772e6368696c6c6564696d6167652e636f6d2f696d616765732f74656e636c617373637461622e6a7067"/></p>
<p>In general the "mechanical" objects, but especially trucks, automobiles and ships were the easiest to classify.</p>
<p>Frogs:
Frogs were generally well classified. The predictor tended to, however, mis-classify birds and cats as frogs.</p>
<p>Trucks:
Trucks were generally well classified. The major problem for the predictor was with automobiles. There was a mutual problem between classifying automobiles as trucks, and trucks as automobiles.</p>
<p>Deer:
Deer were not well classified. The predictor tended to err in predicting deer as either birds, cats, or horses. Intuitively the confusion with horses makes sense.</p>
<p>Automobiles:
As has been mentioned, there was a problem in distinguishing them from trucks.</p>
<p>Birds:
Birds were not generally well classified, the mis-classification being spread amongst frogs, deer and airplanes.</p>
<p>Cats:
Cats were the least well classified. There was a significant mis-classification with dogs.</p>
<p>Dogs:
Dogs were reasonably well classified. The biggest mis-classifications were with cats and birds.</p>
<p>Horses:
Horses were generally well classified. Deer represented the big mis-classification group.</p>
<p>Ships:
Ships were the most well classified group. The biggest mis-classification was with airplanes.</p>
<p>Airplanes:
Airplanes were reasonably well classified. Birds and ships were the largest two groups with which mis-classification ocurred.</p>
<h3>
<a aria-hidden="true" class="anchor" href="#rationale-for-the-cascade-model" id="user-content-rationale-for-the-cascade-model"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z" fill-rule="evenodd"></path></svg></a>Rationale for the Cascade Model</h3>
<p>In general the man-made, or mechanical, groups appeared the most separable from the animal groups. This was the principal reason for the top-level split of the cascade model.</p>
<p>Once the "animal" vs "mechanical" split had been decided upon the rest of the cascade splits were made trading off more easily separable groups whilst keeping the number of categories that the model had to predict as small as possible, in addition to trying to minimize the number of classifiers as a whole.</p>
<p>The mechanical group was therefore handled by a single 4 class model.</p>
<p>Given that there were six categories still left within the animal group it seemed appropriate to sub-classify this, rather than build a single 6 class model. Ideally it would have been useful to group together the large four legged animals and the small four legged animals, and indeed this formed the basis of the split. Unfortunately, frogs and birds needed to be included in this split so they were arbitrarily assigned.</p>

        </div>

    </div>]