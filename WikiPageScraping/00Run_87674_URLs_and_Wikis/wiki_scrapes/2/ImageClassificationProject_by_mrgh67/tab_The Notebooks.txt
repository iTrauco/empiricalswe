[<div class="wiki-body gollum-markdown-content instapaper_body" id="wiki-body">
        <div class="markdown-body">
          <h1>
<a aria-hidden="true" class="anchor" href="#notebook1" id="user-content-notebook1"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z" fill-rule="evenodd"></path></svg></a>Notebook1</h1>
<p>This is an exploratory notebook only.</p>
<p>Important things to note:</p>
<ul>
<li>
<p>All 50000 images in the training set can be loaded into memory with no problems at all.</p>
</li>
<li>
<p>The data labels are obvious and easy to interpret and use.</p>
</li>
<li>
<p>A full color image is read as a .png file. Once loaded it's internal representation is as a np array.</p>
</li>
<li>
<p>Each np array representing an image has dimensions 32 by 32 by 3. This is 32 pixels by 32 pixels by 3 channels - red, green and blue.</p>
</li>
<li>
<p>The full color images are easily converted to grayscale. A grayscale image has np array dimensions of 32 by 32 pixels. Each of the red, green and blue channels have been combined into a single grayscale channel.</p>
</li>
<li>
<p>skimage loads without problems and provides ready access to routines such as edge detection and Otsu thresholding.</p>
</li>
</ul>
<p>As a baseline I ran some experiments.</p>
<p>Using all 50000 images from the training set I trained a simple decision tree classifier.
The data was split into two - 25000 images to train on, and the remaining 25000 images as a test set.
The 32 by 32 pixel structure was unwrapped into a single array of length 1024 for grayscale images and of length 3072 for full color images.</p>
<p>Unmodified raw pixels were used as input into the classifier.</p>
<p>Using the color channels the classifier could accurately predict on the test set with a success rate of 25%.
Using grayscale data only the prediction rate fell to 21%
A 25% classification rate was maintained when just the first 10 principal components were used as input to the classifier.
A final simple experiment was conducted using a simple edge detection filter ("canny" filtering). Using simple edge detection resulted in a drop in the classification rate to 14%</p>
<p>Conclusions:</p>
<ul>
<li>
<p>This was not a trivially easy problem!</p>
</li>
<li>
<p>There is evidence to suggest that there is worthwhile information in the color channels.</p>
</li>
<li>
<p>Likely significant improvement in classification rates is going to be more of a function on the feature extraction than on particular choice of classifer.</p>
</li>
</ul>

        </div>

    </div>]