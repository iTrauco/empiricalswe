[<div class="wiki-body gollum-markdown-content instapaper_body" id="wiki-body">
        <div class="markdown-body">
          <h2>
<a aria-hidden="true" class="anchor" href="#prerequisites" id="user-content-prerequisites"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z" fill-rule="evenodd"></path></svg></a>Prerequisites</h2>
<h4>
<a aria-hidden="true" class="anchor" href="#hardware" id="user-content-hardware"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z" fill-rule="evenodd"></path></svg></a>Hardware</h4>
<p>You will need a machine with an NVidia graphics card capable of CUDA Compute Capability 3.0 or later. See here for a <a href="https://developer.nvidia.com/cuda-gpus" rel="nofollow">comprehensive list</a> of cards and their Compute Capabilities.</p>
<h4>
<a aria-hidden="true" class="anchor" href="#os" id="user-content-os"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z" fill-rule="evenodd"></path></svg></a>OS</h4>
<p>Simplelearn is developed and tested on Linux machines. While it should be able to run on any platform that can run Theano, the following quickstart instructions will be for Linux.</p>
<h2>
<a aria-hidden="true" class="anchor" href="#installation" id="user-content-installation"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z" fill-rule="evenodd"></path></svg></a>Installation</h2>
<p>Follow <a href="http://deeplearning.net/software/theano/install.html" rel="nofollow">these instructions</a> to install Theano and its prerequisites.</p>
<p>Don't forget to set up your <code>~/.theanorc</code> file, particularly the <code>floatX = float32</code> line. The following <code>.theanorc</code> works for me. You may have to change your CUDA line if you have CUDA installed elsewhere:</p>
<pre><code>[global]
floatX = float32
device = cpu

[nvcc]
fastmath = True

[cuda]
root=/usr/local/cuda
</code></pre>
<p>Install <a href="https://developer.nvidia.com/cuda-zone" rel="nofollow">CUDA</a> and <a href="https://developer.nvidia.com/cuDNN" rel="nofollow">cuDNN</a>.</p>
<p>Point Theano to the cuDNN installation directory by adding the following lines in <code>~/.bashrc</code></p>
<pre><code>CUDNN_PATH=/usr/local/share/cudnn  # or wherever else you installed it to
export LIBRARY_PATH=$CUDNN_PATH:$LIBRARY_PATH  # for the static libs
export CPATH=$CUDNN_PATH:$CPATH  # for the .h file
</code></pre>
<p>Install Simplelearn's remaining prerequisites. On Ubuntu:</p>
<pre><code>$ apt-get install python-nose python-h5py python-matplotlib
</code></pre>
<p>Clone simplelearn (this will download a <code>simplelearn/</code> directory to the current directory):</p>
<pre><code>$ git clone https://github.com/SuperElectric/simplelearn.git
</code></pre>
<p>Add the following lines to <code>~/.bashrc</code></p>
<pre><code>export PYTHONPATH=$PYTHONPATH:/home/mkg/projects/simplelearn  # make Simplelearn visible to python
export SIMPLELEARN_DATA_PATH=/home/mkg/datasets/simplelearn/  # simplelearn will download datasets to here
</code></pre>
<h2>
<a aria-hidden="true" class="anchor" href="#running-an-example" id="user-content-running-an-example"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z" fill-rule="evenodd"></path></svg></a>Running an example</h2>
<p>Try running an example program, <code>mnist_conv.py</code>, which trains a small convnet on the <a href="http://yann.lecun.com/exdb/mnist/" rel="nofollow">MNIST</a> hand-written digit dataset. If you haven't downloaded this yet, the script will download it for you. If, after the download, you get output like the following, Simplelearn is up and running.</p>
<pre><code>$ cd simplelearn/simplelearn/
$ THEANO_FLAGS="device=gpu" ./mnist_conv.py --output-prefix tmp_conv
Using gpu device 0: GeForce GTX 780
Misclassification rate: (array([ 0.89522]),)
Average loss: (array([ 0.81343049], dtype=float32),)
Epoch 0 duration: 33.9933919907
Misclassification rate: (array([ 0.06798]),)
Average loss: (array([ 0.15730615], dtype=float32),)
Epoch 1 duration: 33.954059124
Misclassification rate: (array([ 0.03604]),)
Average loss: (array([ 0.10687878], dtype=float32),)
Epoch 2 duration: 34.9537220001
Misclassification rate: (array([ 0.02744]),)
Average loss: (array([ 0.08487143], dtype=float32),)
Epoch 3 duration: 34.1164798737
Misclassification rate: (array([ 0.0242]),)
Average loss: (array([ 0.07189204], dtype=float32),)
Epoch 4 duration: 33.0435481071
Misclassification rate: (array([ 0.0214]),)
Average loss: (array([ 0.06386506], dtype=float32),)
Epoch 5 duration: 33.4460840225
Misclassification rate: (array([ 0.01734]),)
Average loss: (array([ 0.05867916], dtype=float32),)
Epoch 6 duration: 33.986084938
Misclassification rate: (array([ 0.01484]),)
Average loss: (array([ 0.05356075], dtype=float32),)
Epoch 7 duration: 34.0081748962
Misclassification rate: (array([ 0.01428]),)
Average loss: (array([ 0.05282998], dtype=float32),)
Epoch 8 duration: 34.2083411217
Misclassification rate: (array([ 0.0112]),)
Average loss: (array([ 0.05056879], dtype=float32),)
Epoch 9 duration: 34.5561640263
Misclassification rate: (array([ 0.02808]),)
Average loss: (array([ 0.10335245], dtype=float32),)
Epoch 10 duration: 33.8959698677
Misclassification rate: (array([ 0.0159]),)
Average loss: (array([ 0.06666229], dtype=float32),)
Epoch 11 duration: 34.1218860149
Misclassification rate: (array([ 0.01404]),)
Average loss: (array([ 0.06901053], dtype=float32),)
Epoch 12 duration: 33.9835319519
Misclassification rate: (array([ 0.01842]),)
Average loss: (array([ 0.05180062], dtype=float32),)
Epoch 13 duration: 34.0649840832
Misclassification rate: (array([ 0.01212]),)
Average loss: (array([ 0.04371284], dtype=float32),)
Epoch 14 duration: 33.818969965
Misclassification rate: (array([ 0.0121]),)
Average loss: (array([ 0.03589317], dtype=float32),)
Epoch 15 duration: 33.944963932
Misclassification rate: (array([ 0.01116]),)
Average loss: (array([ 0.03545801], dtype=float32),)
Epoch 16 duration: 34.1124851704
Misclassification rate: (array([ 0.00942]),)
Average loss: (array([ 0.03293939], dtype=float32),)
Epoch 17 duration: 34.1240530014
Misclassification rate: (array([ 0.01076]),)
Average loss: (array([ 0.0282425], dtype=float32),)
Epoch 18 duration: 34.0093979836
Misclassification rate: (array([ 0.00704]),)
Average loss: (array([ 0.02285497], dtype=float32),)
Epoch 19 duration: 34.6093080044
Misclassification rate: (array([ 0.00832]),)
Average loss: (array([ 0.02060495], dtype=float32),)
Epoch 20 duration: 33.8041238785
Misclassification rate: (array([ 0.00884]),)
Average loss: (array([ 0.01939964], dtype=float32),)
Epoch 21 duration: 34.0505831242
Misclassification rate: (array([ 0.00896]),)
Average loss: (array([ 0.01759746], dtype=float32),)
Epoch 22 duration: 33.9330868721
Misclassification rate: (array([ 0.0081]),)
Average loss: (array([ 0.01813133], dtype=float32),)
Epoch 23 duration: 33.7240610123
Misclassification rate: (array([ 0.0083]),)
Average loss: (array([ 0.01727406], dtype=float32),)
Epoch 24 duration: 33.9842760563
Misclassification rate: (array([ 0.0073]),)
Average loss: (array([ 0.01564242], dtype=float32),)
Epoch 25 duration: 32.702534914
Misclassification rate: (array([ 0.0076]),)
Average loss: (array([ 0.0160507], dtype=float32),)
Epoch 26 duration: 33.4294950962
Misclassification rate: (array([ 0.0083]),)
Average loss: (array([ 0.01833182], dtype=float32),)
Epoch 27 duration: 34.0452361107
Misclassification rate: (array([ 0.0061]),)
Average loss: (array([ 0.01441866], dtype=float32),)
Epoch 28 duration: 38.6997368336
Misclassification rate: (array([ 0.00768]),)
Average loss: (array([ 0.01302376], dtype=float32),)
Epoch 29 duration: 33.8726279736
Misclassification rate: (array([ 0.00696]),)
Average loss: (array([ 0.01232112], dtype=float32),)
Epoch 30 duration: 34.0908780098
Misclassification rate: (array([ 0.00448]),)
Average loss: (array([ 0.0138682], dtype=float32),)
Epoch 31 duration: 34.3973209858
Misclassification rate: (array([ 0.00604]),)
Average loss: (array([ 0.01088296], dtype=float32),)
Epoch 32 duration: 33.7455711365
Misclassification rate: (array([ 0.00568]),)
Average loss: (array([ 0.01012747], dtype=float32),)
Epoch 33 duration: 34.147236824
Misclassification rate: (array([ 0.00484]),)
Average loss: (array([ 0.01138801], dtype=float32),)
Epoch 34 duration: 33.9404740334
Misclassification rate: (array([ 0.00806]),)
Average loss: (array([ 0.01256544], dtype=float32),)
Epoch 35 duration: 33.9693470001
Misclassification rate: (array([ 0.00494]),)
Average loss: (array([ 0.01213173], dtype=float32),)
Epoch 36 duration: 33.8345551491
Misclassification rate: (array([ 0.00822]),)
Average loss: (array([ 0.01019165], dtype=float32),)
Epoch 37 duration: 33.9026348591
Misclassification rate: (array([ 0.00514]),)
Average loss: (array([ 0.00945748], dtype=float32),)
Epoch 38 duration: 33.87301898
Misclassification rate: (array([ 0.00588]),)
Average loss: (array([ 0.01047164], dtype=float32),)
Epoch 39 duration: 34.1351211071
Misclassification rate: (array([ 0.00536]),)
Average loss: (array([ 0.01231213], dtype=float32),)
Epoch 40 duration: 34.2483770847
Misclassification rate: (array([ 0.00714]),)
Stopped training with message: 0.0 stopping training. Value did not lower by a fraction exceeding 0.00448 for 10 epochs.
</code></pre>

        </div>

        <div class="wiki-footer gollum-markdown-content boxed-group" id="wiki-footer">
          <div class="boxed-group-inner wiki-auxiliary-content markdown-body">
            <p>Copyright (c) 2015 Matthew Koichi Grimes</p>

          </div>
        </div>
    </div>]