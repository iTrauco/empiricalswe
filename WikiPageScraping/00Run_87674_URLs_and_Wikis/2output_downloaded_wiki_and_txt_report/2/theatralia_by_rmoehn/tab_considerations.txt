[<div class="wiki-body gollum-markdown-content instapaper_body" id="wiki-body">
        <div class="markdown-body">
          <h1>
<a aria-hidden="true" class="anchor" href="#considerations" id="user-content-considerations"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z" fill-rule="evenodd"></path></svg></a>Considerations</h1>
<ul>
<li>There is a <a href="requirements#adding-material">scenario</a>, where the user
sits in an archive, a library or at a conference and wants to quickly
add materials to her collection.
<ul>
<li>Do people always have internet access in archives, libraries and
at conferences? Do we need some offline part of the application? (<strong>UO: well, yes, I assume that the offline locations are getting less and less so that the offline part would count as a luxury later on problem</strong>)</li>
<li>If the emphasis is on quickly, would it be useful to provide some
functionality where you first add lots of materials and the
metadata later? (<strong>UO: yes, both should be possible, quick adding unstructured data for later rework an important option</strong>)</li>
<li>Would it be useful the other way around: add lots of metadata and
later the materials themselves? – I could think of a situation
where you scan some things and the scanner saves them on a
pendrive and later you want to add those things in batch and
associate them with the metadata you put in during scanning.(<strong>UO: yes, correct, similar case: you put some metadata of infos you need and ask an assistant to do some web search and link the materials to it</strong>)</li>
</ul>
</li>
<li>The <a href="development">development</a> page says that we should aim for a
high degree of distribution from the start. It sounds as if the
normal thing would be to have only one or a few users per node and
the nodes should somehow be connected. I wonder what benefits we
would have from such an architecture. They should be great enough to
outweigh the resulting difficulties and complexities:
<ul>
<li>Users are much less inclined to use a system if they have to set
it up on their own than if they just have to register somewhere on
the internet. (cf. Diaspora, Friendica)</li>
<li>Users would barely ever undertake to set up the system on their
private computer. – It's offline most of the time, does no
backups, sits behind firewalls.</li>
<li>A multi-node system makes development (including testing) more
complex.
<ul>
<li>Communication and synchronisation between nodes.</li>
<li>Searching for items in distributed databases!</li>
<li>Need those discipline registry things.</li>
</ul>
</li>
<li>
<a href="requirements">Requirements</a> say that there should be an incentive
for libraries, archives, publishers to publish their information
in the system. How do they know which node to use? Should the set
up their own? But they wouldn't researchers, but a completely
different user group.</li>
<li>
<a href="requirements">Requirements</a> say that the system should give an
impression of the state and direction of research in some
discipline area. If you want to get that impression, to which node
do you go? Were do you start looking?</li>
</ul>
</li>
</ul>
<p>(**UO: there seems to be a misunderstanding here, caused by the use of
the word "node". the idea is the following:</p>
<ol>
<li>one instance of the system (i.e. hildesheim/theatralia.de) serving
generally lots of users, it can develop into a widely known address for
theatre research for example and users can simply sign up on the server
to add there profile.</li>
<li>internally though all the different users are not managed by
overarching processes and database but are completely separated from
each other (data and process), so for example, looking up public
entities would not mean looking in the shared database for the public
marked things but sending messages to other users to get the data. for
those instances I used the word "node".</li>
<li>the thinking behind this idea was mainly, that it in the end, this
would mean there is no big difference, whether the users are all on one
server or different instances on the system. communication inside of
"theatralia.de" would be similar to a possible later communication
between "theatralia.de" and "19thcentury.com"**)</li>
</ol>
<ul>
<li>
<a href="requirements">Requirements</a> say that the system should be neither a
complete database nor a publishing platform. They also say that there
should be an incentive for libraries, archives and publishers to
publish their information in the system. How do those two fit
together?</li>
</ul>
<p>(<strong>UO: well, big question, some answers:
a) if actually some academic community uses it widely, publishers might
be interested in having their publications found: without too much work,
they could enter new bibliography data into the system, so if theres a
new dissertation on some subject, it will be linked there, though
actually publishers would probably rather asked the authors to do so,
but that is one and the same.
b) libraries will not use the system for managing data or publishing it,
since they have their own systems, but cooperations should be possible,
that link the system to library contents and catalogues and allow to put
metadata onto those library entities.
c) similar with archives, but most archives are too small and under
financed to have their own good data systems (some still print digital
paper articles and put them into folders to be safe) ... here later on
cooperations might be thinkable.. but again I think, it would have the
focus on interfacing and adding metadata, the "real" data entities being
in statically referencable databases that do not allow much more than
safe storage...</strong>)</p>

        </div>

    </div>]