[<div class="wiki-body gollum-markdown-content instapaper_body" id="wiki-body">
        <div class="markdown-body">
          <p>The purpose of this page is to create some easy-to-reach goalposts that will help kick-start this project. Below are some basic features and capabilities that the first iteration of this project should contain. It will also attempt to define the interfaces between various component.</p>
<p>This project consists of three main components: The web crawler that finds and retrieves job postings, a posting parser that pulls the relevant information out of each job posting found by the web crawler, and the front-end - a website that displays the results.</p>
<h1>
<a aria-hidden="true" class="anchor" href="#web-crawler" id="user-content-web-crawler"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z" fill-rule="evenodd"></path></svg></a>Web Crawler</h1>
<p>For the first iteration, the web crawler will be pretty 'dumb'. This is to ensure that the first iteration can be finished quickly. Probably the simplest way to implement this is by specifying the job posting parent url - the page that has a series of links to job postings - for a few companies.</p>
<p>A good target list of companies would be CUSEC 2015 sponsors. That list exists here: <a href="http://2015.cusec.net/#sponsors" rel="nofollow">http://2015.cusec.net/#sponsors</a>. The goal is to have a web crawler that can be fed each of the parent url's (<em>eg.</em> <a href="http://www.shopify.com/careers" rel="nofollow">http://www.shopify.com/careers</a>) and then it will visit each actual job posting and pull out the raw HTML body. The simplest interface between the web crawler and the posting parser is this raw HTML.</p>
<h1>
<a aria-hidden="true" class="anchor" href="#posting-parser" id="user-content-posting-parser"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z" fill-rule="evenodd"></path></svg></a>Posting Parser</h1>
<p>Again, for the first iteration, the parser component will be very simplistic. The parser will accept raw HTML from the web crawler, and grab the appropriate information (<em>ie.</em> hard- and soft- skills keywords) and place that information into a database. The information gathered should be associated with information about where and from whence it came - date, company, <em>etc.</em></p>
<p>A incredibly simplistic way to implement this would be to pull information from HTML <code>&lt;li&gt;</code> tags. This has some pretty obvious drawbacks, but will give a semblance of information that can be displayed on the front-end. The most important part of this component will be the database relations it defines; this is the interface between the parser and the front-end.</p>
<h1>
<a aria-hidden="true" class="anchor" href="#front-end" id="user-content-front-end"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z" fill-rule="evenodd"></path></svg></a>Front End</h1>
<p>This is where users will be able to view the information. Although it will be ideal to be able to filter the data by a wide variety of criteria, for the first iteration it will be much more limited. Just displaying the raw statistics of the retrieved, such as the number of times a certain tech skill is mentioned, will be good enough. It is probably a good idea to implement at least one filter, such as "view by company", to help test the interface defined by the parser.</p>

        </div>

    </div>]