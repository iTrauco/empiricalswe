Takes an input of a list of github wiki pages to scrape with BeautifulSoup for further analysis.
To run this script: python3 scraping.py




Python/Beautiful soup references:

Accessing a wikipage requires login
https://stackoverflow.com/questions/23102833/how-to-scrape-a-website-which-requires-login-using-python-and-beautifulsoup
https://gist.github.com/ywjno/2642513

Python - Getting all links from a div having a class
https://stackoverflow.com/questions/8616928/python-getting-all-links-from-a-div-having-a-class

Case for when there are many pages (>15 pages, requires expansion)
Parsing a dynamic webpage, need to click on link to see the rest in the table
https://pythonprogramming.net/javascript-dynamic-scraping-parsing-beautiful-soup-tutorial/
https://github.com/snowplow/snowplow/wiki

BeautifulSoup documentation
https://www.crummy.com/software/BeautifulSoup/bs4/doc/

Searching for link with specific word
https://stackoverflow.com/questions/38252434/beautifulsoup-to-find-a-link-that-contains-a-specific-word